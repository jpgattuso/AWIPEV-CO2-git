dyShading(from = TAevents[7], to = TAevents[8], color = "#C2C2C2") %>%
dyShading(from = TAevents[9], to = TAevents[10], color = "#EDEDED") %>%
dyShading(from = TAevents[11], to = TAevents[12], color = "#C2C2C2") %>%
dyAxis("y",valueRange = c(2000, 2550)) %>%
dyHighlight(highlightCircleSize = 8,highlightSeriesBackgroundAlpha = 0.5,hideOnMouseOut = TRUE) %>%
dyOptions( strokeWidth= 0) %>%
dyOptions(drawGrid = TRUE, drawPoints = TRUE,useDataTimezone = TRUE) %>%
dyRangeSelector(height = 30, dateWindow= NULL)
f <- as.data.frame(table(d_all$at))
sum(f$Freq)
# Number of outliers removed in the dataset
# numberOutliers <- length(which((dat_ATnoNA$outliers > 0)))
calib_analyser <-  read.table(paste0(path, "fb_data/Calibration/TA_#1215/measure_CRM_TA.txt"), header = T, dec = ".", as.is = T, sep = ",", fill = TRUE)
# To make the mean
# Keep dates as Character to plot without date gaps.
calib_analyser3 <- calib_analyser %>%
dplyr::filter(analyser == "TA3")
meanTA3 <- calib_analyser3 %>%
group_by(day) %>%
summarise (meanTA = mean(TA))
melt_calib <- melt(calib_analyser, id.vars=c("analyser", "TA_theo", "datetime", "CRM"), measure.vars=c("TA"))
calib_p <- ggplot()+
geom_point(data= melt_calib, aes(x=datetime, y=value, color=factor(CRM), shape= factor(analyser)) , size=3) +
scale_color_manual(values=c("blue","red"))+
# set dashed lines for theoritical CRM
geom_segment(aes(x=1,xend=20,y=2226.16,yend=2226.16), linetype="dashed", color="blue")+
annotate("text", x = 11, y = 2228, label = "Batch #145 = 2226.16", color="blue")+
geom_segment(aes(x=20,xend=23,y=2213.59,yend=2213.59), linetype="dashed", color="red")+
annotate("text", x = 15.5, y = 2213.59, label = "Batch #159 = 2213.59", color="red")+
# set hard lines for measured CRM
geom_segment(aes(x=1,xend=5,y=2254,yend=2254), color="blue") +
annotate("text", x = 3, y = 2249, label = "2254", color="blue")+
geom_segment(aes(x=6,xend=10,y=2251.6,yend=2251.6), color="blue") +
annotate("text", x = 8, y = 2247, label = "2251.6", color="blue")+
geom_segment(aes(x=11,xend=15,y=2190.4,yend=2190.4), color="blue")+
annotate("text", x = 14, y = 2195, label = "2190.4", color="blue")+
geom_segment(aes(x=16,xend=20,y=2203.5,yend=2203.5), color="blue")+
annotate("text", x = 18, y = 2200, label = "2203.5", color="blue")+
geom_segment(aes(x=21,xend=23,y=2224.20,yend=2224.20), color="red")+
annotate("text", x = 22, y = 2230, label = "2224.2", color="red") +
theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1))+
labs(title= "",y=expression(paste("Total alkalinity (Âµmoles.",kg^-1,")")), x="Date", color= "CRM",shape= "Deployed instrument")
ggsave(paste0(path, "fb_figures/TA_Analyser/Calibration/TA_calibration_CRM.png"), calib_p, units="cm")
print(calib_p)
#Interpolation of continuous sensor data to match a maximum of reference data.
TAinterp_all <-approx(d_all$datetime, d_all$AT_filtered, xout=d_all$datetime, method="linear", rule=2)
names(TAinterp_all) <- c("datetime", "AT_filtered_interp")
TAinterp_all <- as.data.frame(TAinterp_all)
d_all$AT_filtered_interp <- TAinterp_all$AT_filtered_interp
# create a column with difference between sensor and ref
d_all <- d_all%>%
dplyr::mutate(diff_ta =  at-AT_filtered_interp )
# create colum with instrument number
d_all <- d_all %>%
dplyr::mutate(TA_period= ifelse(datetime >= "2016-02-26 00:00:00" & datetime < "2017-02-09 12:00:00", "TA1",
ifelse(datetime >= "2017-02-09 12:00:00" & datetime < "2017-03-10 12:00:00", "TA2",
ifelse(datetime >= "2018-01-07 00:00:00" & datetime < "2018-06-20 00:00:00", "TA3",
ifelse(datetime >= "2018-07-31 00:00:00" & datetime < "2018-10-31 00:00:00", "TA4",
ifelse(datetime >= "2019-01-26 00:00:00" , "TA5", "TA0"))))))
#remove outliers
calib_ta_first <- d_all%>%
dplyr::select(datetime, closest_datetime,AT_filtered, AT_filtered_interp, at,diff_ta,TA_period)%>%
dplyr::filter(TA_period =="TA1" & !is.na(at))
#dplyr::filter( !is.na(at))#, diff_ta > -40 & diff_ta < 20 )
# & datetime != "2016-08-18 08:00:00" & datetime != "2016-12-29 12:00:00 ",!is.na(at))
# Parameters of regression
fit <- lm( data=calib_ta_first%>%filter(diff_ta <= 50), diff_ta ~ datetime)
at_slope_TA1 <- round(fit$coefficients[[2]] , digits=6)
at_slope1 <- round(at_slope_TA1 * 3600 *24 * 365.24, digits=2)
at_intercept1 <- round(fit$coefficients[[1]], digits= 2)
# Plot of regression
p <- ggplot(calib_ta_first%>%filter(diff_ta <= 50),aes(datetime,diff_ta)) +
geom_point() + geom_smooth(method='lm', se=FALSE)+
geom_point(data= calib_ta_first%>%filter(diff_ta >= 50), aes(x=datetime, y=diff_ta), color="red")  +
geom_hline(yintercept = 0, linetype="dashed" )+
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
"Slope =",signif(fit$coef[[2]], 5),
"P =",signif(summary(fit)$coef[2,4], 5))) +
ylab("Difference: Reference - Analyser") + xlab("Time") + scale_x_datetime(date_labels = "%b %Y", date_minor_breaks = "month", timezone="UTC")
print(p)
ggsave(paste0(path, "fb_figures/TA_Analyser/Calibration/Diff_ref_TA_first_period.png"), p, units="cm")
#remove outliers and remove period without TA measurements
calib_ta_third <- d_all%>%
dplyr::select(datetime, closest_datetime,AT_filtered, AT_filtered_interp, at,diff_ta, TA_period)%>%
dplyr::filter(TA_period == "TA3" & !is.na(at))
# Parameters of regression
fit <- lm( data=calib_ta_third, diff_ta ~ datetime)
at_slope_TA3 <- round(fit$coefficients[[2]] , digits=8)
at_slope3 <- round(at_slope_TA3 * 3600 *24 * 365.24, digits=2)
at_intercept3 <- round(fit$coefficients[[1]], digits= 2) # pas besoin ici.
# Plot of regression
p <- ggplot(calib_ta_third,aes(x=datetime, y=diff_ta) )+
geom_point() + geom_smooth(method='lm', se=FALSE)+
#geom_point(data= calib_ta_third%>%filter(diff_ta < -40 & diff_ta<20), aes(x=datetime, y=diff_ta), color="red")  +
geom_hline(yintercept = 0, linetype="dashed" )+
geom_vline(xintercept = as.POSIXct("2018-01-08 12:55:00", tz="UTC"), colour="red", linetype = "longdash") +
#geom_text(aes(xintercept=as.POSIXct("2018-01-01 12:55:00"),label="TA "), colour="red", vjust=1.2)+
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5))) + ylab("Difference: Reference - Analyser") + xlab("Time") +
scale_x_datetime( date_labels = "%b %Y", date_minor_breaks = "month", timezone="UTC")
print(p)
ggsave(paste0(path, "fb_figures/TA_Analyser/Calibration/Diff_ref_TA_third_period.png"), p, units="cm")
#remove outliers and remove period without TA measurements
calib_ta_second <- d_all%>%
dplyr::select(datetime, closest_datetime,AT_filtered, AT_filtered_interp, at,diff_ta, TA_period)%>%
dplyr::filter(TA_period == "TA2" & !is.na(at))
mean_offset <- mean(calib_ta_second$diff_ta)
# Correction for the 3 periods is apply
d_all <- d_all%>%
dplyr::mutate(datetime_reg = as.numeric(datetime),
at_intercept = ifelse(TA_period == "TA1", at_intercept1,
ifelse(TA_period == "TA3", at_intercept3, NA)),
at_slope = ifelse(TA_period == "TA1", at_slope_TA1,
ifelse(TA_period == "TA3", at_slope_TA3, NA))
)
d_all <- d_all%>%
dplyr::mutate(TA_reg_corrected = ifelse(TA_period == "TA1", (AT_filtered + (d_all$datetime_reg * d_all$at_slope + at_intercept)),
ifelse(TA_period == "TA2", (AT_filtered + mean_offset),
ifelse(TA_period == "TA3", (AT_filtered + (datetime_reg * at_slope)+ at_intercept), NA))))
at_contros_cleaned_xts <- dplyr::select(d_all, datetime,AT_filtered,at,TA_reg_corrected)
at_contros_cleaned_xts <-  as.xts(at_contros_cleaned_xts, order.by = d_all$datetime)
dygraph(at_contros_cleaned_xts, group = "awipev", main=" Total Alkalinity (in Ferrybox)", ylab="Total alkalinity") %>%
#dySeries("at_contros", color = RColorBrewer::brewer.pal(3, "Set2"), strokeWidth = 0, pointSize=2) %>%
dySeries("AT_filtered", label= "Raw TA", color = "blue", strokeWidth = 0, pointSize=2) %>%
dySeries("TA_reg_corrected", label= "Corrected TA", color = RColorBrewer::brewer.pal(3, "Dark2")[1], strokeWidth = 0, pointSize=2) %>%
dySeries("at", label="TA reference",color = "red", strokeWidth = 0, pointSize=4) %>%
dyEvent(as.POSIXct("2016-05-31 10:00:00", tz="GMT"), "HCl Changed", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2016-06-24 10:00:00", tz="GMT"), "BCG Changed", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2016-02-24 14:00:00", tz="GMT"), "Calibration 1", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2016-09-16 10:00:00", tz="GMT"), "Calibration 2", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2017-03-21 12:00:00", tz="GMT"), "TA analyser changed", labelLoc = "top", color="red") %>%
dyEvent(as.POSIXct("2018-01-08 12:55:00", tz="GMT"), "TA analyser changed #TA-0317-001", labelLoc = "top", color="red") %>%
dyEvent(as.POSIXct("2018-07-31 00:00:00", tz="GMT"), "TA analyser changed #TA-1215-001", labelLoc = "top", color="red") %>%
dyEvent(as.POSIXct("2018-10-30 18:00:00", tz="GMT"), "TA analyser changed #TA-0317-001", labelLoc = "top", color="red") %>%
dyEvent(as.POSIXct("2016-11-15 09:00:00", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2017-02-09 12:20:00", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2017-04-11 06:20:00", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2018-01-22 13:00:12", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2018-05-16 12:39:39", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2018-10-31 10:29:27", tz="GMT"), "CRM measurement", labelLoc = "bottom") %>%
dyEvent(as.POSIXct("2019-01-26 13:25:20", tz="GMT"), "Calibration mode - CRM", labelLoc = "bottom") %>%
#dyOptions(colors = RColorBrewer::brewer.pal(3, "Dark2"), pointSize = 4) %>%
dyShading(from = TAevents[1], to = TAevents[2], color = "#EDEDED") %>%
dyShading(from = TAevents[3], to = TAevents[4], color = "#C2C2C2") %>%
dyShading(from = TAevents[5], to = TAevents[6], color = "#EDEDED") %>%
dyShading(from = TAevents[7], to = TAevents[8], color = "#C2C2C2") %>%
dyShading(from = TAevents[9], to = TAevents[10], color = "#EDEDED") %>%
dyShading(from = TAevents[11], to = TAevents[12], color = "#C2C2C2") %>%
dyAxis("y",valueRange = c(1600, 2450)) %>%
dyHighlight(highlightCircleSize = 8,highlightSeriesBackgroundAlpha = 0.5,hideOnMouseOut = TRUE) %>%
dyOptions( strokeWidth= 0) %>%
dyOptions(drawGrid = TRUE, drawPoints = TRUE,useDataTimezone = TRUE) %>%
dyRangeSelector(height = 30, dateWindow= NULL)
#
Sys.setlocale("LC_ALL", "en_US.UTF-8")
Sys.setenv(TZ='UTC') # on utilise UTC
rm(list = ls())
library(tidyverse)
library(robfilter)
library(seacarb)
library(gridExtra)
library(reshape2)
library(lubridate)
library(lmtest)
library(grid)
library(viridis)
library(dygraphs)
require("knitr")
library("lmodel2")
library(captioner)
library(xts)
library(seismicRoll)
library(scales)
knitr::opts_chunk$set(echo = TRUE)
fig_nums <- captioner()
table_nums <- captioner(prefix = "Table")
#define who is the user and define path
if (Sys.getenv("LOGNAME") == "gattuso") path = "../../pCloud\ Sync/Documents/experiments/exp168_awipev-CO2/"
if (Sys.getenv("LOGNAME") == "samir") path = "../../pCloud\ Sync/exp168_awipev-CO2/"
######## function to make regression plot with model I equation in title
ggreg <- function (fit, point_size=2) {
ggplot(fit$model, aes_string(x = names(fit$model)[2],
y = names(fit$model)[1])) +
geom_point(size = point_size, col = "blue") +
stat_smooth(method = "lm", col = "black") +
labs(title = paste(title, "\nAdj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"; Intercept =",signif(fit$coef[[1]],5 ),
"; Slope =",signif(fit$coef[[2]], 5),
"; P =",signif(summary(fit)$coef[2,4], 5))) +
theme(plot.title = element_text(size=7))
}
#################### which.closest function
which.closest <- function(x, table, ...) {
round(approx(x=table, y=1:length(table), xout=x, ...)$y)
}
#################### Regression function
# function regression plot with model II equation (MA) in title
## Dans labs ajout de la variable title pour mettre title avant chaque graphe
ggreg2 <- function (fit, x, y, point.size=5) { # x and y are the names of the variables
fit_data <- data.frame(fit$x, fit$y)
colnames(fit_data) = c(x, y)
reg <- fit$regression.results[2,] #one selects MA only
intercept <- reg$Intercept
slope <- reg$Slope
ggplot(data = fit_data, aes_string(x = x, y = y)) +
geom_point(size = point.size, col = "blue") +
geom_abline(aes(intercept = fit$regression.results[2,2], slope = fit$regression.results[2,3]),
colour = "blue") +
labs(title = paste(title,"\n Adj R2 = ", signif(fit$rsquare, 3),
"; Intercept =", signif(intercept, 3),
"; Slope =", signif(slope, 3),
"; P =", signif(fit$P.param, 3))) +
theme(plot.title = element_text(size=7))
}
#################### Mytheme
Mytheme <- function(size_labs = 7, face_font="plain") {
theme_bw() +
theme(axis.text.x = element_text(face=face_font, size=size_labs, color="black"),
axis.title.x = element_text(face=face_font, size=size_labs),
axis.text.y = element_text(face=face_font, color="black", size=size_labs),
axis.title.y = element_text(face=face_font, size=size_labs),
axis.ticks.x = element_line(size=0.1),
axis.ticks.y = element_line(size=0.1),
axis.ticks.length = unit(1.1, "mm"),
panel.grid.major = element_line(size = 0.25, color="black", linetype="dashed"),
aspect.ratio = 1 / 2,
plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm")
)
}
ggplotRegression <- function(fit){
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red", se= FALSE) +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
d <- read.table(paste0(path, "fb_data/Discrete_analyses_AT_CT/Discrete_sampling_AWIPEV.csv"), header = T, dec = ".", as.is = T, sep = ";", fill = TRUE)
d$datetime <- as.POSIXct(d$sampling_date, format="%d/%m/%Y %H:%M", tz="UTC")
d$measure_date <- dmy(d$measure_date, tz="UTC")
# Add the flag location: some samples have been collected at the peer. Notes them here.
# Flag 1 = collected on the peer by Niskin and flag 0 = collected in the FB (normal collect)
# And keep data with flag 0 for FB location
d <- d%>%
dplyr::mutate(location_flag = ifelse(datetime == "2016-04-21 09:25:00" | datetime == "2016-02-10 14:00:00" | datetime == "2016-02-17 09:20:00" |datetime == "2016-02-24 14:20:00" | datetime == "2016-02-04 09:30:00" |datetime == "2016-01-27 15:00:00" |datetime == "2016-01-13 13:45:00" |datetime == "2016-01-06 14:10:00" |datetime == "2015-12-24 10:45:00" |datetime == "2015-12-30 13:30:00" |datetime == "2018-01-05 15:20:00" |datetime == "2018-02-02 14:35:00"|datetime == "2018-03-02 14:10:00", 1,0)
)
d <- d%>%
dplyr::filter(location_flag== 0)
# Keep only flag = 2 for at/ct analysis
# Keep only flag = 2 for pH durafet and seaFET.
d <- d%>%
dplyr::mutate(ct= replace(ct, qflag_ct != 2, NA),
at= replace(at, qflag_at != 2, NA),
pH_s_seafet= replace(pH_s_seafet, qflag_pH_s_seafet != 2, NA),
pH_s_durafet= replace(pH_s_durafet, qflag_pH_s_durafet != 2, NA))
# Mercury chloride correction (Dickson et al. 2007, SOP3a)
# AT
d$at <- d$at * 1.0002
#CT
d$ct <- d$ct * 1.0002
# Fill "at/ct" to all line with same day.
at_ct_mean <- d %>%
group_by(datetime)%>%
dplyr::summarize(at_mean = mean(at, na.rm = T),
ct_mean = mean(ct, na.rm = T),
at_sd = sd(at, na.rm = T),
ct_sd = sd(ct, na.rm = T)
)
d <- left_join(d, at_ct_mean, by='datetime')
# Fill the gaps in at_mean with interpolation
TAinterp <-approx(d$datetime, d$at_mean, xout=d$datetime, method="linear", rule=2)
names(TAinterp) <- c("datetime", "at_mean_interp")
TAinterp <- as.data.frame(TAinterp)
d$at_mean_interp <- TAinterp$at_mean_interp
CTinterp <-approx(d$datetime, d$ct_mean, xout=d$datetime, method="linear", rule=2)
names(CTinterp) <- c("datetime", "ct_mean_interp")
CTinterp <- as.data.frame(CTinterp)
d$ct_mean_interp <- CTinterp$ct_mean_interp
# Conversion of spectro pH to a same TÂ°
pH_seafet <- d %>%
dplyr::filter(!is.na(pH_s_seafet))
pH_seafet <- pH_seafet %>%
dplyr::mutate(pH_s_seafet_temp_field = pHinsi(pH=pH_seafet$pH_s_seafet,ALK=pH_seafet$at_mean_interp*1e-6, Tinsi=pH_seafet$temp_field, Tlab=pH_seafet$temp_s_lab, Pinsi= pH_seafet$depth/10, S=pH_seafet$salinity_field,Pt=0,Sit=0))
pH_durafet <- d %>%
dplyr::filter(!is.na(pH_s_durafet))
pH_durafet <- pH_durafet %>%
dplyr::mutate(pH_s_durafet_temp_field = pHinsi(pH=pH_durafet$pH_s_durafet,ALK=pH_durafet$at_mean_interp*1e-6, Tinsi=pH_durafet$temp_field, Tlab=pH_durafet$temp_s_lab, Pinsi= pH_durafet$depth/10, S=pH_durafet$salinity_field,Pt=0,Sit=0))
# create separate seafet/durafet df to join to initial "d" df
pH_seafet_mean <- pH_seafet%>%
dplyr::select(datetime,pH_s_seafet_temp_field)%>%
dplyr::group_by(datetime) %>%
dplyr::summarize(pH_s_seafet_temp_field = mean(pH_s_seafet_temp_field, na.rm = T))
pH_durafet_mean <- pH_durafet%>%
dplyr::select(datetime,pH_s_durafet_temp_field)%>%
dplyr::group_by(datetime) %>%
dplyr::summarize(pH_s_durafet_temp_field = mean(pH_s_durafet_temp_field, na.rm = T))
#  make means in "d" to have same format and call it "discrete"
discrete <- d %>%
dplyr::group_by(datetime) %>%
dplyr::summarize(sal = mean(salinity_field, na.rm = T),
temp = mean(temp_field, na.rm = T),
at_mean_interp = mean(at_mean_interp, na.rm = T),
at = mean(at, na.rm = T),
qflag_at = mean(qflag_at, na.rm = T),
ct_mean_interp = mean(ct_mean_interp, na.rm = T),
ct = mean(ct, na.rm = T),
qflag_ct = mean(qflag_ct, na.rm = T)
)
# join discrete + seafet/durafet
discrete <- left_join(discrete, pH_seafet_mean, by='datetime')
discrete <- left_join(discrete, pH_durafet_mean, by='datetime')
##   *****Attention, temp noted by logisticians in d is FB temp with SBE45 ******
# discrete_steffen <- discrete[c(21:72),1:4]
# write.table( discrete_steffen,"../fb_data/DiscreteTA_for_steffen.txt", sep= ",", dec=".", row.names = FALSE)
carb <- carb(15, discrete$at*1e-6, discrete$ct*1e-6,S=discrete$sal, T=discrete$temp, P=0, Pt=0, Sit=0,k1k2="l", kf="dg", ks="d", pHscale="T", b="u74")
discrete$phcalc<- carb$pH
discrete$pco2calc<- carb$pCO2
# xx <- read_tsv("../fb_server/ny-alesund/data/old/All_sensors_731101_2016-08-20.txt", skip=16, col_names=TRUE)
load(file = paste0(path, "fb_server/shinyroot/AWIPEV-CO2/nydata_hour_shiny.Rdata"))
getwd()
path
# xx <- read_tsv("../fb_server/ny-alesund/data/old/All_sensors_731101_2016-08-20.txt", skip=16, col_names=TRUE)
load(file = paste0(path, "fb_awipev-co2_server/ny-alesund/data/nydata_hour.Rdata"))
#
Sys.setlocale("LC_ALL", "en_US.UTF-8")
Sys.setenv(TZ='UTC') # on utilise UTC
rm(list = ls())
library(tidyverse)
library(robfilter)
library(seacarb)
library(gridExtra)
library(reshape2)
library(lubridate)
library(lmtest)
library(grid)
library(viridis)
library(dygraphs)
require("knitr")
library("lmodel2")
library(captioner)
library(xts)
library(seismicRoll)
library(scales)
knitr::opts_chunk$set(echo = TRUE)
fig_nums <- captioner()
table_nums <- captioner(prefix = "Table")
#define who is the user and define path
if (Sys.getenv("LOGNAME") == "gattuso") path = "../../pCloud\ Sync/Documents/experiments/exp168_awipev-CO2/"
if (Sys.getenv("LOGNAME") == "samir") path = "../../pCloud\ Sync/exp168_awipev-CO2/"
######## function to make regression plot with model I equation in title
ggreg <- function (fit, point_size=2) {
ggplot(fit$model, aes_string(x = names(fit$model)[2],
y = names(fit$model)[1])) +
geom_point(size = point_size, col = "blue") +
stat_smooth(method = "lm", col = "black") +
labs(title = paste(title, "\nAdj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"; Intercept =",signif(fit$coef[[1]],5 ),
"; Slope =",signif(fit$coef[[2]], 5),
"; P =",signif(summary(fit)$coef[2,4], 5))) +
theme(plot.title = element_text(size=7))
}
#################### which.closest function
which.closest <- function(x, table, ...) {
round(approx(x=table, y=1:length(table), xout=x, ...)$y)
}
#################### Regression function
# function regression plot with model II equation (MA) in title
## Dans labs ajout de la variable title pour mettre title avant chaque graphe
ggreg2 <- function (fit, x, y, point.size=5) { # x and y are the names of the variables
fit_data <- data.frame(fit$x, fit$y)
colnames(fit_data) = c(x, y)
reg <- fit$regression.results[2,] #one selects MA only
intercept <- reg$Intercept
slope <- reg$Slope
ggplot(data = fit_data, aes_string(x = x, y = y)) +
geom_point(size = point.size, col = "blue") +
geom_abline(aes(intercept = fit$regression.results[2,2], slope = fit$regression.results[2,3]),
colour = "blue") +
labs(title = paste(title,"\n Adj R2 = ", signif(fit$rsquare, 3),
"; Intercept =", signif(intercept, 3),
"; Slope =", signif(slope, 3),
"; P =", signif(fit$P.param, 3))) +
theme(plot.title = element_text(size=7))
}
#################### Mytheme
Mytheme <- function(size_labs = 7, face_font="plain") {
theme_bw() +
theme(axis.text.x = element_text(face=face_font, size=size_labs, color="black"),
axis.title.x = element_text(face=face_font, size=size_labs),
axis.text.y = element_text(face=face_font, color="black", size=size_labs),
axis.title.y = element_text(face=face_font, size=size_labs),
axis.ticks.x = element_line(size=0.1),
axis.ticks.y = element_line(size=0.1),
axis.ticks.length = unit(1.1, "mm"),
panel.grid.major = element_line(size = 0.25, color="black", linetype="dashed"),
aspect.ratio = 1 / 2,
plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "cm")
)
}
ggplotRegression <- function(fit){
require(ggplot2)
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) +
geom_point() +
stat_smooth(method = "lm", col = "red", se= FALSE) +
labs(title = paste("Adj R2 = ",signif(summary(fit)$adj.r.squared, 5),
"Intercept =",signif(fit$coef[[1]],5 ),
" Slope =",signif(fit$coef[[2]], 5),
" P =",signif(summary(fit)$coef[2,4], 5)))
}
d <- read.table(paste0(path, "fb_data/Discrete_analyses_AT_CT/Discrete_sampling_AWIPEV.csv"), header = T, dec = ".", as.is = T, sep = ";", fill = TRUE)
d$datetime <- as.POSIXct(d$sampling_date, format="%d/%m/%Y %H:%M", tz="UTC")
d$measure_date <- dmy(d$measure_date, tz="UTC")
# Add the flag location: some samples have been collected at the peer. Notes them here.
# Flag 1 = collected on the peer by Niskin and flag 0 = collected in the FB (normal collect)
# And keep data with flag 0 for FB location
d <- d%>%
dplyr::mutate(location_flag = ifelse(datetime == "2016-04-21 09:25:00" | datetime == "2016-02-10 14:00:00" | datetime == "2016-02-17 09:20:00" |datetime == "2016-02-24 14:20:00" | datetime == "2016-02-04 09:30:00" |datetime == "2016-01-27 15:00:00" |datetime == "2016-01-13 13:45:00" |datetime == "2016-01-06 14:10:00" |datetime == "2015-12-24 10:45:00" |datetime == "2015-12-30 13:30:00" |datetime == "2018-01-05 15:20:00" |datetime == "2018-02-02 14:35:00"|datetime == "2018-03-02 14:10:00", 1,0)
)
d <- d%>%
dplyr::filter(location_flag== 0)
# Keep only flag = 2 for at/ct analysis
# Keep only flag = 2 for pH durafet and seaFET.
d <- d%>%
dplyr::mutate(ct= replace(ct, qflag_ct != 2, NA),
at= replace(at, qflag_at != 2, NA),
pH_s_seafet= replace(pH_s_seafet, qflag_pH_s_seafet != 2, NA),
pH_s_durafet= replace(pH_s_durafet, qflag_pH_s_durafet != 2, NA))
# Mercury chloride correction (Dickson et al. 2007, SOP3a)
# AT
d$at <- d$at * 1.0002
#CT
d$ct <- d$ct * 1.0002
# Fill "at/ct" to all line with same day.
at_ct_mean <- d %>%
group_by(datetime)%>%
dplyr::summarize(at_mean = mean(at, na.rm = T),
ct_mean = mean(ct, na.rm = T),
at_sd = sd(at, na.rm = T),
ct_sd = sd(ct, na.rm = T)
)
d <- left_join(d, at_ct_mean, by='datetime')
# Fill the gaps in at_mean with interpolation
TAinterp <-approx(d$datetime, d$at_mean, xout=d$datetime, method="linear", rule=2)
names(TAinterp) <- c("datetime", "at_mean_interp")
TAinterp <- as.data.frame(TAinterp)
d$at_mean_interp <- TAinterp$at_mean_interp
CTinterp <-approx(d$datetime, d$ct_mean, xout=d$datetime, method="linear", rule=2)
names(CTinterp) <- c("datetime", "ct_mean_interp")
CTinterp <- as.data.frame(CTinterp)
d$ct_mean_interp <- CTinterp$ct_mean_interp
# Conversion of spectro pH to a same TÂ°
pH_seafet <- d %>%
dplyr::filter(!is.na(pH_s_seafet))
pH_seafet <- pH_seafet %>%
dplyr::mutate(pH_s_seafet_temp_field = pHinsi(pH=pH_seafet$pH_s_seafet,ALK=pH_seafet$at_mean_interp*1e-6, Tinsi=pH_seafet$temp_field, Tlab=pH_seafet$temp_s_lab, Pinsi= pH_seafet$depth/10, S=pH_seafet$salinity_field,Pt=0,Sit=0))
pH_durafet <- d %>%
dplyr::filter(!is.na(pH_s_durafet))
pH_durafet <- pH_durafet %>%
dplyr::mutate(pH_s_durafet_temp_field = pHinsi(pH=pH_durafet$pH_s_durafet,ALK=pH_durafet$at_mean_interp*1e-6, Tinsi=pH_durafet$temp_field, Tlab=pH_durafet$temp_s_lab, Pinsi= pH_durafet$depth/10, S=pH_durafet$salinity_field,Pt=0,Sit=0))
# create separate seafet/durafet df to join to initial "d" df
pH_seafet_mean <- pH_seafet%>%
dplyr::select(datetime,pH_s_seafet_temp_field)%>%
dplyr::group_by(datetime) %>%
dplyr::summarize(pH_s_seafet_temp_field = mean(pH_s_seafet_temp_field, na.rm = T))
pH_durafet_mean <- pH_durafet%>%
dplyr::select(datetime,pH_s_durafet_temp_field)%>%
dplyr::group_by(datetime) %>%
dplyr::summarize(pH_s_durafet_temp_field = mean(pH_s_durafet_temp_field, na.rm = T))
#  make means in "d" to have same format and call it "discrete"
discrete <- d %>%
dplyr::group_by(datetime) %>%
dplyr::summarize(sal = mean(salinity_field, na.rm = T),
temp = mean(temp_field, na.rm = T),
at_mean_interp = mean(at_mean_interp, na.rm = T),
at = mean(at, na.rm = T),
qflag_at = mean(qflag_at, na.rm = T),
ct_mean_interp = mean(ct_mean_interp, na.rm = T),
ct = mean(ct, na.rm = T),
qflag_ct = mean(qflag_ct, na.rm = T)
)
# join discrete + seafet/durafet
discrete <- left_join(discrete, pH_seafet_mean, by='datetime')
discrete <- left_join(discrete, pH_durafet_mean, by='datetime')
##   *****Attention, temp noted by logisticians in d is FB temp with SBE45 ******
# discrete_steffen <- discrete[c(21:72),1:4]
# write.table( discrete_steffen,"../fb_data/DiscreteTA_for_steffen.txt", sep= ",", dec=".", row.names = FALSE)
carb <- carb(15, discrete$at*1e-6, discrete$ct*1e-6,S=discrete$sal, T=discrete$temp, P=0, Pt=0, Sit=0,k1k2="l", kf="dg", ks="d", pHscale="T", b="u74")
discrete$phcalc<- carb$pH
discrete$pco2calc<- carb$pCO2
# xx <- read_tsv("../fb_server/ny-alesund/data/old/All_sensors_731101_2016-08-20.txt", skip=16, col_names=TRUE)
load(file = paste0(path, "fb_awipev-co2_server/ny-alesund/data/nydata_hour.Rdata"))
# xx <- read_tsv("../fb_server/ny-alesund/data/old/All_sensors_731101_2016-08-20.txt", skip=16, col_names=TRUE)
load(file = paste0(path, "fb_awipev-co2_server/ny-alesund/data/processed/nydata_hour.Rdata"))
# xx <- read_tsv("../fb_server/ny-alesund/data/old/All_sensors_731101_2016-08-20.txt", skip=16, col_names=TRUE)
load(file = paste0(path, "fb_awipev-co2_server/ny-alesund/data/processed/nydata_hour.Rdata"))
#load(file = paste0(path, "fb_server/shinyroot/AWIPEV-CO2/nydata_hour_shiny.Rdata"))
#load(file = "../fb_server/shinyroot/AWIPEV-CO2/nydata_shiny.Rdata") #d
# load = d_hour
d_hour <- d_hour %>%
dplyr::select(-date) %>%
dplyr::mutate(AT = ifelse(datetime > "2016-02-26 12:00:00", AT, NA), # beginning of data series for AT
AT = ifelse(AT == "NaN", NA, AT), #3 columns are character
pH_AT = ifelse(pH_AT == "NaN", NA, pH_AT),
PCO2_Corr_Zero2 = ifelse(PCO2_Corr_Zero2 %in% c("NaN", 66666), NA, PCO2_Corr_Zero2)
) %>%
dplyr::rename(at_contros=AT, ph_at_contros=pH_AT, pco2_contros=PCO2_corr_contros_filtered, zero_contros=PCO2_Corr_Zero2,
sal_fb=Salinity_filtered, temp_fb=Temperature_filtered, pH_durafet=HW_pH1_filtered, temp_insitu=Temp_SBE38_filtered)
